{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9357add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified content written to '/Users/noahritfeld/Documents/Main/Preprocessing/DSL_Model_A.txt'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_quotation_marks(input_path):\n",
    "    # Read the content of the input file\n",
    "    with open(input_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Use regular expression to selectively remove standalone double quotes\n",
    "    processed_content = re.sub(r'(?<!\")\"(?!\")', '', content)\n",
    "\n",
    "    # Open the same file in write mode to overwrite its content\n",
    "    with open(input_path, 'w') as file:\n",
    "        file.write(processed_content)\n",
    "\n",
    "    print(f\"Modified content written to '{input_path}'\")\n",
    "\n",
    "# Example usage\n",
    "data1_path = \"/Users/Documents/Main/Preprocessing/DSL_Model_A.txt\"\n",
    "remove_quotation_marks(data1_path)\n",
    "\n",
    "\n",
    "#remove only \"single\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e571d9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified content written to '/Users/noahritfeld/Documents/Main/Preprocessing/DSL_Model_A.txt'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_duplicate_quotation_marks(input_path):\n",
    "    # Read the content of the input file\n",
    "    with open(input_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Use regular expression to remove one of two consecutive double quotes\n",
    "    processed_content = re.sub(r'(\"\")', '\"', content)\n",
    "\n",
    "    # Open the same file in write mode to overwrite its content\n",
    "    with open(input_path, 'w') as file:\n",
    "        file.write(processed_content)\n",
    "\n",
    "    print(f\"Modified content written to '{input_path}'\")\n",
    "\n",
    "# Example usage\n",
    "data1_path = \"/Users/Documents/Main/Preprocessing/DSL_Model_A.txt\"\n",
    "remove_duplicate_quotation_marks(data1_path)\n",
    "\n",
    "\n",
    "\n",
    "#Remove duplicates \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fc2cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pre_and_postunit_quotes(input_file):\n",
    "    with open(input_file, 'r') as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    with open(input_file, 'w') as outfile:\n",
    "        for line in lines:\n",
    "            if \"PreUnit:\" in line or \"PostUnit:\" in line:\n",
    "                # Remove quotation marks from the line\n",
    "                line = line.replace('\"', '')\n",
    "            outfile.write(line)\n",
    "\n",
    "# Specify your file path\n",
    "file_path = \"/Users/Documents/Main/Preprocessing/DSL_Model_A.txt\"\n",
    "\n",
    "# Example usage:\n",
    "remove_pre_and_postunit_quotes(file_path)\n",
    "\n",
    "#only in case when the data contains PostUnit: \"value\" or PostUnit: \"value\" with quotation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c50dd518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been modified and saved to suffix_text.txt\n",
      "commbined data written to '/Users/noahritfeld/Documents/Main/Match_and_Merge/Method_Model_B.txt'\n"
     ]
    }
   ],
   "source": [
    "#re module, which stands for regular expressions, to search for and replace specific patterns in input_processing.txt\n",
    "import re\n",
    "\n",
    "# Define file paths\n",
    "input_file_path = \"/Users/Documents/Main/Preprocessing/DSL_Model_B.txt\"\n",
    "output_file_path = \"/Users/Documents/Main/Preprocessing/DSL_Model_B_with_Suffix.txt\"\n",
    "\n",
    "# Read data from the input file\n",
    "with open(input_file_path, 'r') as file:\n",
    "    data = file.read()\n",
    "    \n",
    "# Define a regular expression pattern to match and replace the Text lines\n",
    "pattern = r'Order:(\\d+)\\s+Text:\\s+\"(.*?)\"'\n",
    "#The re.sub function is then used to replace each match of the specified pattern in the input_processing.txt\n",
    "modified_data = re.sub(pattern, r'Order:\\1\\nText_\\1: \"\\2\"', data)\n",
    "\n",
    "# Define a regular expression pattern to match and replace the Order lines\n",
    "order_pattern = r'Order:(\\d+)'\n",
    "modified_data = re.sub(order_pattern, r'Order_\\1:\\1', modified_data)\n",
    "\n",
    "# Write the modified data to a temporary file\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(modified_data)\n",
    "\n",
    "print(\"Data has been modified and saved to suffix_text.txt\")\n",
    "\n",
    "# Parse modified data\n",
    "current_section = None\n",
    "topics = []\n",
    "indicators = []\n",
    "questions = []\n",
    "\n",
    "\n",
    "with open(output_file_path, \"r\") as file:\n",
    "    current_subsection = {}\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"Topics:\") or line.startswith(\"Indicators:\") or line.startswith(\"Questions:\"):\n",
    "            current_section = line.strip()\n",
    "        elif line:\n",
    "            # Check if there are enough values to unpack\n",
    "            if \":\" in line:\n",
    "                key, value = map(str.strip, line.split(\":\", 1))\n",
    "                current_subsection[key] = value\n",
    "        elif current_subsection:\n",
    "            if current_section == \"Topics:\":\n",
    "                topics.append(current_subsection)\n",
    "            elif current_section == \"Indicators:\":\n",
    "                indicators.append(current_subsection)\n",
    "            elif current_section == \"Questions:\":\n",
    "                questions.append(current_subsection)\n",
    "            current_subsection = {}\n",
    "\n",
    "# Initialize a list to store combined data\n",
    "combined_data = []\n",
    "\n",
    "# Iterate over each topic and indicator to find matches\n",
    "for topic in topics:\n",
    "    topic_id = topic.get(\"Topic_id\", \"\")\n",
    "    topic_name = topic.get(\"Name\", \"\")\n",
    "    topic_description = topic.get(\"Description\", \"\")\n",
    "    \n",
    "    for indicator in indicators:\n",
    "        indicator_id = indicator.get(\"Indicator_id\", \"\")\n",
    "        indicator_topic = indicator.get(\"Topic\", \"\")\n",
    "        indicator_name = indicator.get(\"Name\", \"\")\n",
    "        indicator_description = indicator.get(\"Description\", \"\")\n",
    "        indicator_type = indicator.get(\"Indicator_type\", \"\")\n",
    "        indicator_data_type = indicator.get(\"DataType\", \"\")\n",
    "        \n",
    "        # Check if \"topic_id\" matches with \"Indicator\" attribute \"Topic\"\n",
    "        if topic_id == indicator_topic:\n",
    "            # Check if \"Indicator_type\" is Direct or there is a corresponding question\n",
    "            if indicator_type == \"Direct\":\n",
    "                for question in questions:\n",
    "                    question_id = question.get(\"Question_id\", \"\")\n",
    "                    question_name = question.get(\"Name\", \"\")\n",
    "                    question_description = question.get(\"Description\", \"\")\n",
    "                    question_mandatory = question.get(\"IsMandatory\", \"\")\n",
    "                    question_ui_component = question.get(\"UIComponent\", \"\")\n",
    "                    question_order = question.get(\"Order\", \"\")\n",
    "                    question_instruction = question.get(\"Instruction\", \"\")\n",
    "                    \n",
    "                    # Check if \"Indicator_id\" matches with \"Question\" attribute \"Indicator\"\n",
    "                    if indicator_id == question.get(\"Indicator\"):\n",
    "                        combined_subsection = {\n",
    "                            **{f\"topic_{key}\": value for key, value in topic.items()},\n",
    "                            **{f\"indicator_{key}\": value for key, value in indicator.items()},\n",
    "                            **{f\"question_{key}\": value for key, value in question.items()}\n",
    "                        }\n",
    "                        combined_data.append(combined_subsection)\n",
    "            elif indicator_type == \"Indirect\":\n",
    "                combined_subsection = {\n",
    "                    **{f\"topic_{key}\": value for key, value in topic.items()},\n",
    "                    **{f\"indicator_{key}\": value for key, value in indicator.items()}\n",
    "                }\n",
    "                combined_data.append(combined_subsection)\n",
    "                \n",
    "                \n",
    "# Define file paths \n",
    "combined_output_file_path = \"/Users/Documents/Main/Match_and_Merge/Method_Model_B.txt\"\n",
    "# Write the combined data to the output file\n",
    "with open(combined_output_file_path, \"w\") as output_file:\n",
    "    for subsection in combined_data:\n",
    "        for key, value in subsection.items():\n",
    "            output_file.write(f\"{key}:{value}\\n\")\n",
    "        output_file.write(\"\\n\")\n",
    "\n",
    "print(f\"commbined data written to '{combined_output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f4de70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
